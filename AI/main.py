# main.py (ì™„ì„±í˜• ë¦¬íŒ©í† ë§ v2: answer_with_sources ê°•ì œ, ì„¸ì…˜ ì „ë‹¬ í™•ì‹¤í™”, DOC ë°˜ë³µ/ì¦ì‹ ë°©ì§€, ìŠ¤í‚¤ë§ˆ í†µì¼)
import os
import re
import time
import uuid
from typing import Any, Dict, List, Optional

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from langchain_core.messages import AIMessage, HumanMessage


# -------------------------------------------------------------------------
# [Import] rag_pipeline.pyì—ì„œ í•„ìš”í•œ ì²´ì¸/ìœ í‹¸ ê°€ì ¸ì˜¤ê¸°
#  - ì´ main.pyëŠ” answer_with_sources()ê°€ "í•„ìˆ˜"ì…ë‹ˆë‹¤. (ê·¼ê±° ë¶ˆì¼ì¹˜/ì¤‘ë³µê²€ìƒ‰ ë°©ì§€)
# -------------------------------------------------------------------------
try:
    from rag_pipeline import (
        get_rag_chain,
        get_writing_chain,
        get_router_chain,
        get_session_history,
        store,
        answer_with_sources,  # âœ… í•„ìˆ˜
    )
except Exception as e:
    try:
        from src.mediguide_rag.rag_pipeline import (
            get_rag_chain,
            get_writing_chain,
            get_router_chain,
            get_session_history,
            store,
            answer_with_sources,  # âœ… í•„ìˆ˜
        )
    except Exception as e2:
        raise RuntimeError(
            "rag_pipelineì—ì„œ answer_with_sourcesë¥¼ import í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            "âœ… rag_pipeline.pyì— answer_with_sources(question: str, session_id: str) -> dict\n"
            "   {'answer': str, 'mode': 'SOLUTION'|'INTERVIEW', 'docs': List[Document], 'sources': List[dict] (optional)}\n"
            "ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€í•˜ì„¸ìš”.\n"
            f"import error1={e}\nimport error2={e2}"
        )


# -------------------------------------------------------------------------
# [Setup] FastAPI ì•± ì´ˆê¸°í™”
# -------------------------------------------------------------------------
app = FastAPI(title="MediGuide AI Server", version="1.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë°ëª¨ OK. ìš´ì˜ì´ë©´ ë„ë©”ì¸ ì œí•œ ê¶Œì¥.
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -------------------------------------------------------------------------
# [Loading] AI ëª¨ë¸ ì²´ì¸ ë¡œë“œ
# -------------------------------------------------------------------------
print("ğŸš€ AI ëª¨ë¸ ì²´ì¸ ë¡œë”© ì¤‘...")
rag_chain = get_rag_chain()
writing_chain = get_writing_chain()
router_chain = get_router_chain()
print("âœ… ë¡œë”© ì™„ë£Œ! ì„œë²„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")


# -------------------------------------------------------------------------
# Request/Response Models
# -------------------------------------------------------------------------
MAX_QUERY_CHARS = 2500  # í”„ë¡ íŠ¸ì—ì„œë„ ì œí•œ ê¶Œì¥

class Question(BaseModel):
    query: str = Field(..., description="User input")
    session_id: str = Field("default_user", description="Session identifier")

class SourceItem(BaseModel):
    evidence_no: Optional[int] = None
    title: str
    dept: str
    section: str
    seq: Optional[str] = None
    content_preview: str

class ChatResponse(BaseModel):
    request_id: str
    session_id: str
    type: str  # "chat" | "document"
    answer: str
    document_content: Optional[str] = None
    mode: Optional[str] = None  # "SOLUTION" | "INTERVIEW"
    sources: List[SourceItem] = []
    latency_ms: int


# -------------------------------------------------------------------------
# Helpers
# -------------------------------------------------------------------------
def _sanitize_session_id(session_id: str) -> str:
    s = (session_id or "").strip()
    if not s:
        return "default_user"
    if len(s) > 64:
        s = s[:64]
    return s

def _sanitize_query(q: str) -> str:
    q = (q or "").strip()
    if not q:
        raise HTTPException(status_code=422, detail="queryê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if len(q) > MAX_QUERY_CHARS:
        raise HTTPException(
            status_code=413,
            detail=f"queryê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ {MAX_QUERY_CHARS}ì)",
        )
    return q

def _safe_preview(text: str, n: int = 220) -> str:
    t = (text or "").strip().replace("\n", " ")
    if len(t) > n:
        return t[:n] + "..."
    return t

def _build_sources_from_docs(docs: List[Any], preview_chars: int = 220) -> List[Dict[str, Any]]:
    """
    rerankëœ docsë¡œ UI-friendly sources ìƒì„±.
    - evidence_noëŠ” 1..Nìœ¼ë¡œ ê³ ì •
    """
    sources: List[Dict[str, Any]] = []
    for i, doc in enumerate(docs or [], 1):
        md = getattr(doc, "metadata", {}) or {}
        sources.append(
            {
                "evidence_no": i,
                "title": md.get("title", "ê´€ë ¨ íŒë¡€/ìë£Œ"),
                "dept": md.get("dept", md.get("medical_dept", "ì§„ë£Œê³¼ ì—†ìŒ")),
                "section": md.get("section", "section ì—†ìŒ"),
                "seq": md.get("seq"),
                "content_preview": _safe_preview(getattr(doc, "page_content", ""), preview_chars),
            }
        )
    return sources

_DOC_LIKE_PATTERNS = [
    r"^ì œëª©:\s*ì˜ë£Œê³¼ì‹¤",
    r"\bì‹ ì²­ì¸\b",
    r"\bí”¼ì‹ ì²­ì¸\b",
    r"\bì˜ë£Œë¶„ìŸ\s*ì¡°ì •ì‹ ì²­ì„œ\b",
    r"\bì†í•´ë°°ìƒ\s*ì²­êµ¬\b",
    r"\bì¦ê±°\s*ìë£Œ\b",
    r"\bìš”ì²­\s*ì‚¬í•­\b",
    r"\[ì‘ì„±ì¼\]",
    r"ë¬¸ì„œ ì‘ì„±ì„ ìœ„í•´ ì•„ë˜ ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•©ë‹ˆë‹¤",
]

def _is_doc_like_ai_message(text: str) -> bool:
    """
    Writerê°€ ë§Œë“  'ë¬¸ì„œ ë³¸ë¬¸'ì´ íˆìŠ¤í† ë¦¬ì— ëˆ„ì ë˜ë©´,
    ë‹¤ìŒ ë¬¸ì„œ ìš”ì²­ì—ì„œ ë°˜ë³µ/ì¦ì‹ ë¬¸ì œê°€ ìƒê¹€ â†’ Writer ì…ë ¥ì—ì„œ ì œì™¸.
    """
    t = (text or "").strip()
    if len(t) < 200:
        return False
    for p in _DOC_LIKE_PATTERNS:
        if re.search(p, t, flags=re.IGNORECASE | re.MULTILINE):
            return True
    # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ë¬¸ì„œì¼ í™•ë¥  ë†’ìŒ
    if len(t) > 2500:
        return True
    return False

def _history_to_text_for_writer(session_id: str, max_turns: int = 14) -> str:
    """
    Writerì— ë„£ì„ íˆìŠ¤í† ë¦¬ë¥¼ "ìƒë‹´ ì¤‘ì‹¬"ìœ¼ë¡œ ì •ë¦¬.
    - AI ë¬¸ì„œ ê²°ê³¼(DOC-like)ëŠ” ì œì™¸
    - ìµœê·¼ max_turns í„´ë§Œ ì‚¬ìš©
    """
    history = get_session_history(session_id)
    if not history.messages:
        return "ì´ì „ ëŒ€í™” ê¸°ë¡ ì—†ìŒ."

    # ìµœê·¼ Nê°œë§Œ
    msgs = history.messages[-max_turns:] if len(history.messages) > max_turns else history.messages

    lines: List[str] = []
    turn_idx = 0
    for msg in msgs:
        role = "ì˜ë¢°ì¸" if msg.type == "human" else "ë³€í˜¸ì‚¬"

        # âœ… AI ë¬¸ì„œ ê²°ê³¼ëŠ” ì œì™¸ (ë°˜ë³µ/ì¦ì‹ ë°©ì§€)
        if msg.type != "human" and _is_doc_like_ai_message(msg.content):
            continue

        turn_idx += 1
        lines.append(f"### Turn {turn_idx} ({role})\n{msg.content}\n")

    return "\n".join(lines) if lines else "ì´ì „ ëŒ€í™” ê¸°ë¡ ì—†ìŒ."

def _ensure_session(session_id: str) -> None:
    _ = get_session_history(session_id)


# -------------------------------------------------------------------------
# [API] í†µí•© ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸
#  - CHAT: answer_with_sources()ë§Œ ì‚¬ìš© (ì¤‘ë³µê²€ìƒ‰/ê·¼ê±° ë¶ˆì¼ì¹˜ ì œê±°)
#  - DOC: writer ì…ë ¥ì—ì„œ ë¬¸ì„œ ê²°ê³¼ ì œê±° + ì„¸ì…˜ ì €ì¥ ì•ˆì •í™”
# -------------------------------------------------------------------------
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: Question):
    request_id = str(uuid.uuid4())
    t0 = time.perf_counter()

    session_id = _sanitize_session_id(request.session_id)
    query = _sanitize_query(request.query)

    print(f"\nğŸ“© [{request_id}] Session={session_id} | Query={query}")

    # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ í•­ìƒ ì¤€ë¹„
    _ensure_session(session_id)

    # 1) Router
    try:
        t_router0 = time.perf_counter()
        intent = router_chain.invoke({"question": query}).strip().upper()
        t_router1 = time.perf_counter()
        print(f"ğŸ¤– [{request_id}] Router={intent} ({int((t_router1-t_router0)*1000)}ms)")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Router ì˜¤ë¥˜: {str(e)}")

    # -----------------------------------------------------------------
    # [Case A] DOC
    # -----------------------------------------------------------------
    if "DOC" in intent:
        print(f"ğŸ“ [{request_id}] ë¬¸ì„œ ì‘ì„± ëª¨ë“œ ì§„ì…")

        try:
            history_text = _history_to_text_for_writer(session_id=session_id, max_turns=14)

            # âœ… â€œğŸ”´ í˜„ì¬ ìƒíƒœâ€ ê°™ì€ ë°˜ë³µ í† í°ì„ ë§¤ë²ˆ ëˆ„ì í•˜ì§€ ì•Šë„ë¡, ì…ë ¥ êµ¬ì¡°ë¥¼ ê³ ì •
            full_context = (
                f"[ìƒë‹´ ìš”ì•½/ëŒ€í™” ë‚´ì—­]\n{history_text}\n\n"
                f"[ì˜ë¢°ì¸ì˜ í˜„ì¬ ìš”ì²­(ìµœìš°ì„ )]\n{query}\n"
            )

            t_doc0 = time.perf_counter()
            document_content = writing_chain.invoke({"chat_history": full_context})
            t_doc1 = time.perf_counter()

            # âœ… ë©”ëª¨ë¦¬ ì €ì¥: í•­ìƒ ì €ì¥ë˜ë„ë¡
            hist = get_session_history(session_id)
            hist.add_message(HumanMessage(content=query))
            hist.add_message(AIMessage(content=document_content))

            latency_ms = int((time.perf_counter() - t0) * 1000)
            print(
                f"âœ… [{request_id}] DOC ìƒì„± ì™„ë£Œ "
                f"doc={int((t_doc1-t_doc0)*1000)}ms total={latency_ms}ms"
            )

            return {
                "request_id": request_id,
                "session_id": session_id,
                "type": "document",
                "answer": "ìš”ì²­í•˜ì‹  ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ë¬¸ì„œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "document_content": document_content,
                "mode": None,
                "sources": [],
                "latency_ms": latency_ms,
            }

        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"DOC ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    # -----------------------------------------------------------------
    # [Case B] CHAT (RAG)
    # -----------------------------------------------------------------
    print(f"ğŸ’¬ [{request_id}] ìƒë‹´ ëª¨ë“œ ì§„ì…")

    try:
        # âœ… ë‹¨ì¼ ì§„ì‹¤ ì†ŒìŠ¤: rag_pipelineì—ì„œ ìµœì¢… mode/docsë¥¼ í•¨ê»˜ ë°˜í™˜
        t_rag0 = time.perf_counter()
        out = answer_with_sources(query, session_id=session_id)
        t_rag1 = time.perf_counter()

        answer = (out or {}).get("answer", "") or ""
        mode = (out or {}).get("mode")  # "SOLUTION"|"INTERVIEW"

        # 1) rag_pipelineì´ docsë¥¼ ì£¼ë©´ docsë¡œ sources ìƒì„±
        docs = (out or {}).get("docs", []) or []
        sources = _build_sources_from_docs(docs)

        # 2) rag_pipelineì´ sources(dict ë¦¬ìŠ¤íŠ¸)ë¥¼ ì§ì ‘ ì£¼ëŠ” êµ¬í˜„ì´ë¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©
        #    (í•„ë“œê°€ ë” í’ë¶€í•  ìˆ˜ ìˆìŒ)
        if (out or {}).get("sources"):
            sources = (out or {}).get("sources")

        # âœ… ì„¸ì…˜ ì „ë‹¬ í™•ì‹¤í™”: (rag_chain ë‚´ë¶€ì—ì„œë„ session_idë¥¼ ì“°ëŠ” ê²½ìš° ëŒ€ë¹„)
        # answer_with_sourcesì—ì„œ ì´ë¯¸ ì²˜ë¦¬í–ˆê² ì§€ë§Œ, ë°©ì–´ì ìœ¼ë¡œ ê¸°ë¡ë§Œ ë³´ì¥
        # (ëŒ€ë¶€ë¶„ RunnableWithMessageHistoryê°€ ìë™ ê¸°ë¡)
        _ensure_session(session_id)

        latency_ms = int((time.perf_counter() - t0) * 1000)
        print(
            f"âœ… [{request_id}] RAG ì™„ë£Œ mode={mode} "
            f"rag={int((t_rag1-t_rag0)*1000)}ms total={latency_ms}ms sources={len(sources)}"
        )

        return {
            "request_id": request_id,
            "session_id": session_id,
            "type": "chat",
            "answer": answer,
            "document_content": None,
            "mode": mode,
            "sources": sources,
            "latency_ms": latency_ms,
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"CHAT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")


# -------------------------------------------------------------------------
# [API] ì¶”ì²œ ì§ˆë¬¸ (Chips)
# -------------------------------------------------------------------------
@app.get("/suggested_questions")
def get_suggestions():
    return {
        "questions": [
            "ë°±ë‚´ì¥ ìˆ˜ìˆ  ë¶€ì‘ìš© íŒë¡€ ì•Œë ¤ì¤˜",
            "ì§€ê¸ˆ ìƒë‹´ ë‚´ìš©ìœ¼ë¡œ ë‚´ìš©ì¦ëª…ì„œ ì¨ì¤˜",
            "ì˜ë£Œë¶„ìŸì¡°ì • ì‹ ì²­ ë°©ë²•ì´ ë­ì•¼?",
            "ì„¤ëª… ì˜ë¬´ ìœ„ë°˜ì´ ì¸ì •ëœ ì‚¬ë¡€ ìˆì–´?",
        ]
    }


# -------------------------------------------------------------------------
# [API] ëŒ€í™” ë‚´ì—­ ì¡°íšŒ (+ limit ì§€ì›)
# -------------------------------------------------------------------------
@app.get("/history/{session_id}")
async def get_history(session_id: str, limit: int = Query(50, ge=1, le=200)):
    session_id = _sanitize_session_id(session_id)
    hist = get_session_history(session_id)

    messages = hist.messages[-limit:] if hist.messages else []
    return {
        "session_id": session_id,
        "count": len(messages),
        "history": [
            {"role": "user" if m.type == "human" else "ai", "content": m.content}
            for m in messages
        ],
    }


# -------------------------------------------------------------------------
# ì‹¤í–‰:
#   uv run uvicorn main:app --reload
# -------------------------------------------------------------------------



