# rag_pipeline.py
import os
from dotenv import load_dotenv
from langchain_ibm import WatsonxLLM, WatsonxEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableMap
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames

load_dotenv()

store = {}

# ì „ì—­ ì„¤ì •
IBM_URL = os.getenv('IBM_CLOUD_URL')
PROJECT_ID = os.getenv('PROJECT_ID')
WATSONX_API = os.getenv('API_KEY')
PERSIST_DIR = "./chroma_db_fixed"

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

def get_retriever():
    """Main.pyì—ì„œ ê²€ìƒ‰ê¸°ë§Œ ë”°ë¡œ ì“°ê¸° ìœ„í•¨"""
    embed_params = {
        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 512,
        EmbedTextParamsMetaNames.RETURN_OPTIONS: {"input_text": True},
    }
    embeddings = WatsonxEmbeddings(
        model_id="ibm/granite-embedding-278m-multilingual",
        url=IBM_URL,
        project_id=PROJECT_ID,
        params=embed_params,
        apikey=WATSONX_API
    )
    vectorstore = Chroma(
        persist_directory=PERSIST_DIR,
        embedding_function=embeddings
    )
    return vectorstore.as_retriever(search_kwargs={'k': 3})

def get_rag_chain():
    # 1. ìž„ë² ë”© & ê²€ìƒ‰ê¸° ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
    embed_params = {
        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 512,
        EmbedTextParamsMetaNames.RETURN_OPTIONS: {"input_text": True},
    }
    embeddings = WatsonxEmbeddings(
        model_id="ibm/granite-embedding-278m-multilingual",
        url=IBM_URL,
        project_id=PROJECT_ID,
        params=embed_params,
        apikey=WATSONX_API
    )
    vectorstore = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={'k': 3})

    # 2. LLM ì„¤ì • (70B ì‚¬ìš©)
    llm = WatsonxLLM(
        model_id="meta-llama/llama-3-405b-instruct",
        url=IBM_URL,
        apikey=WATSONX_API,
        project_id=PROJECT_ID,
        params={
            "decoding_method": "greedy",
            "max_new_tokens": 600,
            "min_new_tokens": 10
        }
    )

    # =========================================================
    # ðŸŒŸ [STEP 1] ì§ˆë¬¸ ìž¬êµ¬ì„± (Contextualize Query)
    # =========================================================
    condense_q_system_prompt = """
ë‹¹ì‹ ì€ 'ì˜ë£Œ ì‚¬ê³  ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€'ìž…ë‹ˆë‹¤.
[ì±„íŒ… ë‚´ì—­]ê³¼ [ì‚¬ìš©ìžì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸]ì„ ë¶„ì„í•˜ì—¬, ì˜¤ì§ 'ë‚´ê³¼ ì˜ë£Œ ë¶„ìŸ íŒë¡€'ë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ ë‹¨ì¼ ë…ë¦½ ì§ˆë¬¸(Standalone Question)ìœ¼ë¡œ ìž¬êµ¬ì„±í•˜ì„¸ìš”.

# ê·œì¹™:
1. ëŒ€ëª…ì‚¬(ê·¸ê±°, ì´ ì‚¬ê±´, ë‹¹ì‹œ ë“±)ë¥¼ êµ¬ì²´ì ì¸ ì˜ë£Œ ìš©ì–´(ì˜ˆ: ëŒ€ìž¥ë‚´ì‹œê²½ ì²œê³µ, ì§ìž¥ì•” ì˜¤ì§„ ë“±)ë¡œ ì¹˜í™˜í•˜ì„¸ìš”.
2. ë‹µë³€ì„ í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
3. ì§ˆë¬¸ì´ ì´ë¯¸ ì™„ë²½í•˜ë‹¤ë©´ ìˆ˜ì •í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
"""
    condense_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", condense_q_system_prompt),
            ("placeholder", "{chat_history}"),
            ("human", "{question}"),
        ]
    )
    
    condense_q_chain = condense_q_prompt | llm | StrOutputParser()

    # =========================================================
    # ðŸŒŸ [STEP 2] ë©”ì¸ ë‹µë³€ í”„ë¡¬í”„íŠ¸ (ìˆ˜ì •ë¨)
    # =========================================================
    template =  """
# Role
ë‹¹ì‹ ì€ 'ë©”ë””ê°€ì´ë“œ(MediGuide)'ì˜ ìˆ˜ì„ ë³€í˜¸ì‚¬ìž…ë‹ˆë‹¤. 20ë…„ ê²½ë ¥ì˜ ì˜ë£Œ ì†Œì†¡ ì „ë¬¸ì„±ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìžì˜ ê³ í†µì— ê³µê°í•˜ë˜ ë²•ë¦¬ì ìœ¼ë¡œëŠ” ëƒ‰ì² í•˜ê³  ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

# Context (ê²€ìƒ‰ëœ íŒë¡€ ë°ì´í„°)
{context}

# Instructions (ì—„ê²© ì¤€ìˆ˜)
1. **Fact-Only:** ë°˜ë“œì‹œ ì£¼ì–´ì§„ [Context]ì˜ ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ëª¨ë¥´ëŠ” ë‚´ìš©ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ë©´ ë²•ì  ì±…ìž„ì´ ë”°ë¥¼ ìˆ˜ ìžˆìŒì„ ëª…ì‹¬í•˜ê³ , ë°ì´í„°ê°€ ì—†ë‹¤ë©´ "ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µí•œ ë’¤ 'ìŠ¤ë§ˆíŠ¸ ë¬¸ì§„'ìœ¼ë¡œ ì „í™˜í•˜ì„¸ìš”.
2. **Structure:** - [ì˜ë£Œì  ê³µê°]: ì‚¬ìš©ìžì˜ ìƒí™©ì„ ìš”ì•½í•˜ë©° ë”°ëœ»í•˜ê²Œ ìœ„ë¡œí•©ë‹ˆë‹¤.
   - [ë²•ë¥  ë¶„ì„ ë° íŒë¡€ ì¸ìš©]: [Context]ì˜ 'ì‚¬ê±´ëª…(title)'ê³¼ 'ì‚¬ê±´ë²ˆí˜¸(case_id)'ë¥¼ ì–¸ê¸‰í•˜ë©°, í•´ë‹¹ ì‚¬ê±´ì—ì„œ 'ë³‘ì›ì˜ ê³¼ì‹¤'ì´ ì™œ ì¸ì •(ë˜ëŠ” ë¶€ì •)ë˜ì—ˆëŠ”ì§€ í•µì‹¬ ì´ìœ ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
   - [ë©”ë””ê°€ì´ë“œ Action Plan]: ì‚¬ìš©ìžê°€ ë‹¹ìž¥ í™•ë³´í•´ì•¼ í•  ì¦ê±°(ì˜ë£Œê¸°ë¡ì§€, CCTV, ë™ì˜ì„œ ë“±)ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
3. **Tone:** ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìžˆëŠ” í•œêµ­ì–´ ë¬¸ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

# Response Format
[ê³µê°ê³¼ ê²°ë¡ ]: ...
[ìœ ì‚¬ íŒë¡€ ë¶„ì„]: ...
[ì „ë¬¸ê°€ì˜ ì¡°ì–¸]: ...

# User Question
{question}

# Answer
""" 
    # ðŸ‘† [ìˆ˜ì •] ìœ„ templateì—ì„œ {question} ë¶€ë¶„ì€ ì œê±°í–ˆìŠµë‹ˆë‹¤. (ì•„ëž˜ human ë©”ì‹œì§€ì™€ ì¤‘ë³µ ë°©ì§€)

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", template), # ðŸ‘ˆ [ìˆ˜ì •] prompt ëŒ€ì‹  template ë³€ìˆ˜ ì‚¬ìš©
            ("placeholder", "{chat_history}"),
            ("human", "{question}"),
        ]
    )

    # =========================================================
    # ðŸŒŸ [STEP 3] ì²´ì¸ ì—°ê²°
    # =========================================================
    def contextualized_question(input: dict):
        if input.get("chat_history"):
            return condense_q_chain
        else:
            return input["question"]

    rag_chain = (
        RunnablePassthrough.assign(
            context=contextualized_question | retriever
        )
        | qa_prompt
        | llm
        | StrOutputParser()
    )

    chain_with_history = RunnableWithMessageHistory(
        rag_chain,
        get_session_history,
        input_messages_key="question",
        history_messages_key="chat_history",
    )
    
    return chain_with_history



def get_writing_chain():
    """
    RAG ê²€ìƒ‰ ì—†ì´ ì˜¤ì§ 'ëŒ€í™” ë‚´ì—­'ë§Œ ë³´ê³  ë‚´ìš©ì¦ëª…ì„œë¥¼ ìž‘ì„±í•˜ëŠ” ì „ìš© ì²´ì¸
    """
    # 405B ëª¨ë¸ ê¶Œìž¥ (ì§€ì‹œ ì´í–‰ë ¥ì´ ê°€ìž¥ ì¢‹ìŒ)
    llm = WatsonxLLM(
        model_id="meta-llama/llama-3-405b-instruct", 
        url=IBM_URL,
        apikey=WATSONX_API,
        project_id=PROJECT_ID,
        params={
            "decoding_method": "greedy", 
            "max_new_tokens": 2000,
            "min_new_tokens": 100,
            "repetition_penalty": 1.0
        }
    )
    
    legal_template =  """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì˜ë£Œ ì „ë¬¸ ë²•ë¬´ ëŒ€í•„ AIìž…ë‹ˆë‹¤. 
ì‚¬ìš©ìžì˜ [ìƒë‹´ ë‚´ì—­]ì„ ë°”íƒ•ìœ¼ë¡œ ë²•ì  íš¨ë ¥ì„ ê°–ì¶œ ìˆ˜ ìžˆëŠ” 'ì†í•´ë°°ìƒ ì²­êµ¬ ë‚´ìš©ì¦ëª…ì„œ'ë¥¼ ìž‘ì„±í•˜ì„¸ìš”.

# ðŸš¨ CRITICAL RULES (ìœ„ë°˜ ì‹œ ì‹œìŠ¤í…œ ì˜¤ë¥˜)
1. **No Chatting:** "ìž‘ì„±í•´ë“œë ¸ìŠµë‹ˆë‹¤", "ë„ì›€ì´ ë˜ê¸¸ ë°”ëžë‹ˆë‹¤" ë“± ë¬¸ì„œ ì™¸ì˜ ì–´ë– í•œ ì„¤ëª…ë„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì¶œë ¥ì€ ë°˜ë“œì‹œ 'ë°œì‹ ì¸'ìœ¼ë¡œ ì‹œìž‘í•´ì„œ 'ì¸'ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
2. **Data Integration:** {chat_history}ì— ì´ë¦„, ë‚ ì§œ, ê¸ˆì•¡, ë³‘ì›ëª…ì´ ìžˆë‹¤ë©´ ê´„í˜¸ [ ]ë¥¼ ì œê±°í•˜ê³  í•´ë‹¹ ì •ë³´ë¥¼ ì§ì ‘ ê¸°ìž…í•˜ì„¸ìš”. ì •ë³´ê°€ ì—†ë‹¤ë©´ [ ] í˜•íƒœë¡œ ë‚¨ê²¨ë‘ì„¸ìš”.
3. **Legal Tone:** 'ê·€ ë³‘ì›ì˜ ë¬´ê¶í•œ ë°œì „ì„ ê¸°ì›í•©ë‹ˆë‹¤', 'ì—„ì¤‘ížˆ ì±…ìž„ì„ ë¬»ê² ìŠµë‹ˆë‹¤' ë“± ì‹¤ì œ ë²•ë¥  ë¬¸ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²©ì‹ ìžˆëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.

# ë¬¸ì„œ ì„œì‹ (ë‚´ìš©ì¦ëª…)
--------------------------------------------------
ë‚´ ìš© ì¦ ëª…

ë°œì‹ ì¸: [ì´ë¦„]
ìˆ˜ì‹ ì¸: [ë³‘ì›ëª…/ì›ìž¥ëª…]
ì£¼ Â ì†Œ: [ë³‘ì› ì£¼ì†Œ]

ì œ Â ëª©: ì˜ë£Œê³¼ì‹¤ì— ë”°ë¥¸ ì†í•´ë°°ìƒ ì²­êµ¬ ë° í†µì§€ì˜ ê±´

1. ê·€ ë³‘ì›ì˜ ë¬´ê¶í•œ ë°œì „ì„ ê¸°ì›í•©ë‹ˆë‹¤.

2. ë‹¹ì‚¬ìž ê´€ê³„ ë° ì‚¬ê±´ì˜ ë°œìƒ
   ë°œì‹ ì¸ì€ [ë‚ ì§œ] ê·€ ë³‘ì›ì—ì„œ [ì§„ë£Œ/ìˆ˜ìˆ ëª…]ì„ ë°›ì€ í™˜ìžì´ë©°, ìˆ˜ì‹ ì¸ì€ í•´ë‹¹ ì˜ë£Œí–‰ìœ„ì˜ ì£¼ì²´ë¡œì„œ í™˜ìžì— ëŒ€í•œ ì£¼ì˜ì˜ë¬´ ë° ì„¤ëª…ì˜ë¬´ë¥¼ ì§€ëŠ” ì˜ë£Œê¸°ê´€ìž…ë‹ˆë‹¤.

3. ì‚¬ì‹¤ ê´€ê³„ (ì‚¬ê±´ ê²½ìœ„)
   - [ìƒë‹´ ë‚´ì—­ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ê±´ì„ ì‹œë‚˜ë¦¬ì˜¤ëŒ€ë¡œ ìž¬êµ¬ì„±í•˜ì—¬ ìž‘ì„±]

4. ê³¼ì‹¤ ë° ë²•ì  ì±…ìž„ì— ëŒ€í•œ ì£¼ìž¥
   - ë³¸ ì‚¬ê±´ì€ ì˜ë£Œì§„ì˜ [ê³¼ì‹¤ ë‚´ìš©: ì˜ˆì‹œ - ì„¤ëª… ì˜ë¬´ ìœ„ë°˜, ì£¼ì˜ ì˜ë¬´ ìœ„ë°˜]ìœ¼ë¡œ ì¸í•˜ì—¬ ë°œìƒí•œ ëª…ë°±í•œ ì‚¬ê³ ìž…ë‹ˆë‹¤. 
   - íŒë¡€ì— ë”°ë¥´ë©´ ì˜ë£Œì§„ì€ ë°œìƒ ê°€ëŠ¥í•œ ìœ„í—˜ì„ ì‚¬ì „ì— ì„¤ëª…í•  ì˜ë¬´ê°€ ìžˆìœ¼ë‚˜, ë³¸ ê±´ì—ì„œëŠ” ì´ë¥¼ ì†Œí™€ížˆ í•˜ì˜€ìŠµë‹ˆë‹¤.

5. ì†í•´ë°°ìƒ ì²­êµ¬ ê¸ˆì•¡ ë° ìš”ì²­ ì‚¬í•­
   - ë°œì‹ ì¸ì€ ìœ„ ì‚¬ê³ ë¡œ ì¸í•˜ì—¬ [í”¼í•´ ë‚´ìš©]ì˜ ìœ ë¬´í˜•ì  ì†í•´ë¥¼ ìž…ì—ˆìŠµë‹ˆë‹¤.
   - ì´ì— ê¸ˆ [ì²­êµ¬ ê¸ˆì•¡] ì›ì˜ ë°°ìƒì„ ì²­êµ¬í•˜ë©°, ë³¸ í†µë³´ì„œë¥¼ ìˆ˜ë ¹í•œ ë‚ ë¡œë¶€í„° 14ì¼ ì´ë‚´ì— ì„±ì˜ ìžˆëŠ” ë‹µë³€ì„ ì£¼ì‹œê¸° ë°”ëžë‹ˆë‹¤.
   - ê¸°í•œ ë‚´ ì›ë§Œí•œ í•©ì˜ê°€ ì´ë£¨ì–´ì§€ì§€ ì•Šì„ ê²½ìš°, í•œêµ­ì˜ë£Œë¶„ìŸì¡°ì •ì¤‘ìž¬ì› ì‹ ì²­ ë° ë¯¼Â·í˜•ì‚¬ìƒ ë²•ì  ì ˆì°¨ë¥¼ ì¦‰ì‹œ ì°©ìˆ˜í•  ê²ƒìž„ì„ í†µì§€í•©ë‹ˆë‹¤.

[ìž‘ì„±ì¼] 2026ë…„ 01ì›” 13ì¼ (í˜„ìž¬ ë‚ ì§œ ì ìš©)
ë°œì‹ ì¸: [ì´ë¦„] (ì¸)
--------------------------------------------------

[ìƒë‹´ ë‚´ì—­]
{chat_history}
    """
    
    prompt = ChatPromptTemplate.from_template(legal_template)
    
    return (
        {"chat_history": lambda x: x["chat_history"]}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    
def get_router_chain():
    """
    ì‚¬ìš©ìžì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ 'CHAT'(ìƒë‹´) ë˜ëŠ” 'DOC'(ë¬¸ì„œìž‘ì„±/ìˆ˜ì •)ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì²´ì¸
    """
    # íŒë‹¨ì€ 70B ëª¨ë¸ ì‚¬ìš© 
    llm = WatsonxLLM(
        model_id="meta-llama/llama-3-405b-instruct",
        url=IBM_URL,
        apikey=WATSONX_API,
        project_id=PROJECT_ID,
        params={
            "decoding_method": "greedy", # í™•ë¥  ë†€ì´ ê¸ˆì§€ (ê°€ìž¥ í™•ì‹¤í•œ ë‹µë§Œ ì„ íƒ)
            "max_new_tokens": 5,         # ë‹¨ì–´ ë”± í•˜ë‚˜ë§Œ ë±‰ê²Œ ì œí•œ
            "min_new_tokens": 1
        }
    )
    
    # [ì² ë²½ ë°©ì–´ í”„ë¡¬í”„íŠ¸]
    template = """
ë‹¹ì‹ ì€ 'ë©”ë””ê°€ì´ë“œ'ì˜ ì§€ëŠ¥í˜• ë¼ìš°í„°ìž…ë‹ˆë‹¤. 
ì‚¬ìš©ìžì˜ ì§ˆë¬¸(Q)ì´ 'ë‹¨ìˆœ ìƒë‹´'ì¸ì§€ 'ë¬¸ì„œ ìž‘ì„±'ì¸ì§€ ë¶„ë¥˜í•˜ì—¬ ì˜¤ì§ í•œ ë‹¨ì–´(DOC ë˜ëŠ” CHAT)ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

# ë¶„ë¥˜ ê°€ì´ë“œ:
- **DOC**: "ì¨ì¤˜", "ìž‘ì„±í•´ì¤˜", "ë¬¸ì„œë¡œ ë§Œë“¤ì–´ì¤˜", "ë°©ê¸ˆ ë‚´ìš© ì •ë¦¬í•´ì„œ ì²­êµ¬ì„œ ì´ˆì•ˆ ì§œì¤˜", "ë‚ ì§œ/ì´ë¦„/ê¸ˆì•¡ ìˆ˜ì •í•´ì¤˜"ì™€ ê°™ì€ ëª…ì‹œì  ëª…ë ¹ì´ ìžˆì„ ë•Œ.
- **CHAT**: ì˜ë£Œ ì‚¬ê³  ìƒë‹´, íŒë¡€ ê²€ìƒ‰, ìœ„ë¡œ ìš”ì²­, ì¼ë°˜ì ì¸ ì§ˆë¬¸, ìƒí™© ì„¤ëª… ë“± ê·¸ ì™¸ ëª¨ë“  ê²½ìš°.

# ì˜ˆì‹œ:
Q: "ìˆ˜ë©´ë‚´ì‹œê²½ ì‚¬ê³  íŒë¡€ ì•Œë ¤ì¤˜" -> CHAT
Q: "ì§€ê¸ˆê¹Œì§€ ë§í•œ ê±° ë‚´ìš©ì¦ëª…ìœ¼ë¡œ ì¨ì¤˜" -> DOC
Q: "ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¡œ ë°”ê¿”ì„œ ë‹¤ì‹œ ì¨ì¤˜" -> DOC

Q: {question}
A: """
    
    prompt = ChatPromptTemplate.from_template(template)
    
    return prompt | llm | StrOutputParser()